This experiment is meant to 
	i) explore the value of LDA in clustering Wikipedia pages
	into groups of related pages about events in real life and
	ii) explore the value of using different term weights
	such as tf and tf-idf and different metrics as a similarity
	measure such as cosine distance, KL divergence, weighted sum,
	and language models.


I. LDA.

I chose the Mallet software to run LDA on our data set. It was used before
to run the K-means clustering on our data set, so it seems to be a natural
selection to me.

The JAVA source files used to run K-means are located at: src/mallet.
I will add a new module to run LDA on our data set.

First, I looked at the official website of the software:
http://mallet.cs.umass.edu/

The algorithms and stuff Mallet supports are various:
	For document classification: NaÃ¯ve Bayes, Max-ent, Decision Tress.
	For sequence tagging: HMMs, Max-ent MMs, CRFs
	For topic modeling: LDA, Pachinko Allocation, Hierarchical LDA.
	For numerical optimizations: Limited Memory BFGS

It seemed all too complicated. So I decided to run a thing as simplest as
possible first. The next thing is the one I decided to run:
	The goal is to cluster the articles selected on January 27, 2009.
	The source articles: data/articles/2009-01-27
	The number of clusters: 50

	The commands:
		Importing documents:
			$MALLET/bin/mallet import-dir --input data/articles/2009-01-27 --output data/mallet/input/2009-01-27.articles.mallet --keep-sequence --remove-stopwords
		Building a model:
			$MALLET/bin/mallet train-topics --input data/mallet/input/2009-01-27.articles.mallet --num-topics 50 --output-state data/mallet/output/2009-01-27.topic-state.gz --output-model data/mallet/output/2009-01-27.model --output-doc-topics data/mallet/output/2009-01-27.doc-topics --output-topic-keys data/mallet/output/2009-01-27.topic-keys --inferencer-filename 2009-01-27.inferencer
			
			Total time: 3 minutes 57 seconds
		The doc-topics file is the one I wanted. It has the topic number in the third column. I wrote a script to convert the format of the output into mine:
			src/cluster/lda/extract_cluster.sh
			
		Generating clustering for January 27, 2009:
			./extract_cluster.sh 50 ../../../data/mallet/output/2009-01-27.doc-topics > ../../../data/clusters/lda/2009-01-27.cluster
			
		Evaluating the result:
			cd src/cluster/eval
			./eval.py ../../../data/clusters/bahn/cluster0127.txt ../../../data/clusters/lda/2009-01-27.cluster
		
			Evaluation result:
				gold standard: ../../../data/clusters/bahn/cluster0127.txt
				clustering: ../../../data/clusters/lda/2009-01-27.cluster
				clusters of gold standard: 43
				clusters of test set: 44
				Multiplicity BCubed precision: 0.3753
				Multiplicity BCubed recall:    0.3206
				Multiplicity BCubed F-score:   0.3458
				
		Batch running:
			Importing documents:
				(cd $WIKITOPICS)
				for DATE in 2009-01-27 2009-02-10 2009-04-19 2009-05-12 2009-10-12; do $MALLET/bin/mallet import-dir --input data/articles/$DATE --output data/mallet/input/$DATE.articles.mallet --keep-sequence --remove-stopwords; done
			Running LDA:
				for DATE in 2009-01-27 2009-02-10 2009-04-19 2009-05-12 2009-10-12; do $MALLET/bin/mallet train-topics --input data/mallet/input/$DATE.articles.mallet --num-topics 50 --output-state data/mallet/output/$DATE.topic-state.gz --output-model data/mallet/output/$DATE.model --output-doc-topics data/mallet/output/$DATE.doc-topics --output-topic-keys data/mallet/output/$DATE.topic-keys --inferencer-filename data/mallet/output/$DATE.inferencer; done
				
				Fail: I ran LDA on the whole data of the five days. This took a lot of time. Probably the time running lda takes varies according to how long it takes until it converges.
					2009-01-27: Total time: 14 minutes 24 seconds
					2009-02-10: Total time: 17 minutes 14 seconds
					2009-04-19: Total time: 14 minutes 10 seconds
					2009-05-12: Total time: 16 minutes 53 seconds
					2009-10-12: Total time: 2 hours 18 seconds
			Generating clusters:
				for DATE in 2009-01-27 2009-02-10 2009-04-19 2009-05-12 2009-10-12; do src/cluster/lda/extract_cluster.sh 50 data/mallet/output/$DATE.doc-topics > data/clusters/lda/$DATE.clusters; done
			Evaluation:
				cd src/cluster/eval; ./eval.sh lda | ./tabularize.pl
		
			I found an error while running evaluation. I re-run everything again:
				ccb	lda	0127	38	44	0.5152	0.3484	0.4157
				ccb	lda	0210	52	46	0.4512	0.3913	0.4191
				ccb	lda	0419	51	44	0.5397	0.5730	0.5559
				ccb	lda	0512	44	44	0.5036	0.2247	0.3108
				ccb	lda	1012	58	46	0.4793	0.4311	0.4540
				ben	lda	0127	34	44	0.6061	0.2451	0.3490
				ben	lda	0210	58	46	0.4350	0.4911	0.4613
				ben	lda	0419	59	44	0.4663	0.5956	0.5230
				ben	lda	0512	34	44	0.6506	0.2115	0.3192
				ben	lda	1012	65	46	0.3608	0.5687	0.4415
				bahn	lda	0127	43	44	0.4432	0.3330	0.3802
				bahn	lda	0210	63	46	0.3659	0.5070	0.4250
				bahn	lda	0419	63	44	0.4504	0.7088	0.5508
				bahn	lda	0512	37	44	0.6024	0.2196	0.3219
				bahn	lda	1012	63	46	0.3937	0.5682	0.4651
		Using LDA with k=75:
		    Learning a topic model:
                cd $WIKITOPICS
                for DATE in 2009-01-27 2009-02-10 2009-04-19 2009-05-12 2009-10-12; do $MALLET/bin/mallet train-topics --input data/mallet/input/$DATE.articles.mallet --num-topics 75 --output-state data/mallet/lda-75/$DATE.topic-state.gz --output-model data/mallet/lda-75/$DATE.model --output-doc-topics data/mallet/lda-75/$DATE.doc-topics --output-topic-keys data/mallet/lda-75/$DATE.topic-keys --inferencer-filename data/mallet/lda-75/$DATE.inferencer; done
            Generating clusters:
                cd src/cluster/lda
                for DATE in 2009-01-27 2009-02-10 2009-04-19 2009-05-12 2009-10-12; do ./extract_cluster.sh 75 ../../../data/mallet/lda-75/$DATE.doc-topics > ../../../data/clusters/lda-75/$DATE.clusters; done
            Evaluation:
                cd ../eval
                ./eval.sh lda-75 | ./tabularize.pl
            Results:
                ccb	lda-75	0127	38	59	0.5857	0.2810	0.3798
                ccb	lda-75	0210	52	61	0.4706	0.2545	0.3303
                ccb	lda-75	0419	51	57	0.5486	0.4436	0.4905
                ccb	lda-75	0512	44	57	0.5692	0.1894	0.2842
                ccb	lda-75	1012	58	60	0.5025	0.2548	0.3381
                ben	lda-75	0127	34	59	0.6429	0.2066	0.3127
                ben	lda-75	0210	58	61	0.4510	0.3156	0.3713
                ben	lda-75	0419	59	57	0.4343	0.4633	0.4483
                ben	lda-75	0512	34	57	0.7308	0.1972	0.3106
                ben	lda-75	1012	65	60	0.4328	0.4643	0.4480
                bahn	lda-75	0127	43	59	0.4429	0.2587	0.3266
                bahn	lda-75	0210	63	61	0.4265	0.3663	0.3941
                bahn	lda-75	0419	63	57	0.4629	0.5404	0.4986
                bahn	lda-75	0512	37	57	0.6385	0.1784	0.2789
                bahn	lda-75	1012	63	60	0.5075	0.4533	0.4788

		Using LDA with k=100:
		    Learning a topic model:
                cd $WIKITOPICS
                for DATE in 2009-01-27 2009-02-10 2009-04-19 2009-05-12 2009-10-12; do $MALLET/bin/mallet train-topics --input data/mallet/input/$DATE.articles.mallet --num-topics 100 --output-state data/mallet/lda-100/$DATE.topic-state.gz --output-model data/mallet/lda-100/$DATE.model --output-doc-topics data/mallet/lda-100/$DATE.doc-topics --output-topic-keys data/mallet/lda-100/$DATE.topic-keys --inferencer-filename data/mallet/lda-100/$DATE.inferencer; done
            Generating clusters:
                cd src/cluster/lda
                for DATE in 2009-01-27 2009-02-10 2009-04-19 2009-05-12 2009-10-12; do ./extract_cluster.sh 100 ../../../data/mallet/lda-100/$DATE.doc-topics > ../../../data/clusters/lda-100/$DATE.clusters; done
            Evaluation:
                cd ../eval
                ./eval.sh lda-100 | ./tabularize.pl
            Results:
                ccb	lda-100	0127	38	68	0.4727	0.1650	0.2446
                ccb	lda-100	0210	52	72	0.4706	0.1945	0.2753
                ccb	lda-100	0419	51	69	0.6545	0.3201	0.4299
                ccb	lda-100	0512	44	62	0.5246	0.1327	0.2119
                ccb	lda-100	1012	58	69	0.5818	0.2287	0.3283
                ben	lda-100	0127	34	68	0.5455	0.0925	0.1581
                ben	lda-100	0210	58	72	0.4314	0.2821	0.3411
                ben	lda-100	0419	59	69	0.5455	0.3678	0.4393
                ben	lda-100	0512	34	62	0.7705	0.1531	0.2554
                ben	lda-100	1012	65	69	0.5697	0.4451	0.4997
                bahn	lda-100	0127	43	68	0.4000	0.1815	0.2497
                bahn	lda-100	0210	63	72	0.4314	0.3377	0.3788
                bahn	lda-100	0419	63	69	0.5818	0.4456	0.5047
                bahn	lda-100	0512	37	62	0.6721	0.1317	0.2203
                bahn	lda-100	1012	63	69	0.6485	0.4347	0.5205

II. K-means.

The point is to run K-means with TF/IDF.

Found a paper written by Michelson and Knoblock:
	Unsupervised information extraction from unstructured, ungrammatical data sources on the World Wide Web
	http://www.springerlink.com/content/2l7lw5gt0885g871/fulltext.pdf
	
	Distances included in the paper:
		Jensen-Shannon distance, Jaro-Winkler similarity, TF/IDF, and Jaro-Winkler TF/IDF.
	Implentation: SecondString package.

My plan:
	To revise src/cluster/kmeans/ClusterFiles.java so that it uses varioius term weighting and distance metric.
		- shows the clustering paramters like the number of dimensions.
		
Experiments:
	- First I want to make sure the pipes that LDA pipeline used does not affect the results.
		- put in additional pipes into the pipeline: Target2Label, SaveDataInSource.
		- run clustering and see if the results remain the same.
		Commands:
			cd /Users/bahn/work/wikitopics/src/cluster/kmeans/ClusterFiles
			./batchrun
			diff /Users/bahn/work/wikitopics/data/clusters/kmeans-centroid . | grep -v Source\ directory
		- they are exactly the same
	- Try various term weighting and 
		- try tf, idf, and tfidf
		Commands:
			cd /Users/bahn/work/wikitopics/src/cluster/kmeans/ClusterFiles
			
			Generating clusters:
			- basic settings:
				./batchrun
				diff /Users/bahn/work/wikitopics/data/clusters/kmeans-centroid . | grep -v Only\ in\ .: | grep -v Source\ directory
				mkdir -p /Users/bahn/work/wikitopics/data/clusters/kmeans-tf
				mv kmeans* /Users/bahn/work/wikitopics/data/clusters/kmeans-tf
			- cosine distance and idf
				./batchrun --weighting idf
				diff /Users/bahn/work/wikitopics/data/clusters/kmeans-centroid . | grep -v Only\ in\ .:
				mkdir -p /Users/bahn/work/wikitopics/data/clusters/kmeans-idf
				mv kmeans* /Users/bahn/work/wikitopics/data/clusters/kmeans-idf
			- cosine distance and tfidf
				./batchrun --weighting tfidf
				diff /Users/bahn/work/wikitopics/data/clusters/kmeans-centroid . | grep -v Only\ in\ .:
				mkdir -p /Users/bahn/work/wikitopics/data/clusters/kmeans-tfidf
				mv kmeans* /Users/bahn/work/wikitopics/data/clusters/kmeans-tfidf
		
			Evaluating the clusters:
				cd src/cluster/eval
				./eval_kmeans.sh | ./tabularize.pl
				./eval_kmeans.sh -tf | ./tabularize.pl
				./eval_kmeans.sh -idf | ./tabularize.pl
				./eval_kmeans.sh -tfidf | ./tabularize.pl
				
		Results:
		- original
			ccb	kmeans	0127	38	50	0.5830	0.4438	0.5040
			ccb	kmeans	0210	52	50	0.5635	0.5125	0.5368
			ccb	kmeans	0419	51	50	0.6431	0.5451	0.5901
			ccb	kmeans	0512	44	50	0.7369	0.4118	0.5283
			ccb	kmeans	1012	58	50	0.5172	0.5051	0.5111
			ben	kmeans	0127	34	50	0.7976	0.2983	0.4342
			ben	kmeans	0210	58	50	0.4746	0.5611	0.5143
			ben	kmeans	0419	59	50	0.5009	0.5156	0.5081
			ben	kmeans	0512	34	50	0.8923	0.3672	0.5203
			ben	kmeans	1012	65	50	0.4195	0.5962	0.4925
			bahn	kmeans	0127	43	50	0.4626	0.4467	0.4545
			bahn	kmeans	0210	63	50	0.4508	0.6383	0.5284
			bahn	kmeans	0419	63	50	0.5276	0.6684	0.5897
			bahn	kmeans	0512	37	50	0.8615	0.3938	0.5405
			bahn	kmeans	1012	63	50	0.5006	0.6235	0.5553
		- tf
			ccb	kmeans-tf	0127	38	50	0.5830	0.4438	0.5040
			ccb	kmeans-tf	0210	52	50	0.5635	0.5125	0.5368
			ccb	kmeans-tf	0419	51	50	0.6431	0.5451	0.5901
			ccb	kmeans-tf	0512	44	50	0.7369	0.4118	0.5283
			ccb	kmeans-tf	1012	58	50	0.5172	0.5051	0.5111
			ben	kmeans-tf	0127	34	50	0.7976	0.2983	0.4342
			ben	kmeans-tf	0210	58	50	0.4746	0.5611	0.5143
			ben	kmeans-tf	0419	59	50	0.5009	0.5156	0.5081
			ben	kmeans-tf	0512	34	50	0.8923	0.3672	0.5203
			ben	kmeans-tf	1012	65	50	0.4195	0.5962	0.4925
			bahn	kmeans-tf	0127	43	50	0.4626	0.4467	0.4545
			bahn	kmeans-tf	0210	63	50	0.4508	0.6383	0.5284
			bahn	kmeans-tf	0419	63	50	0.5276	0.6684	0.5897
			bahn	kmeans-tf	0512	37	50	0.8615	0.3938	0.5405
			bahn	kmeans-tf	1012	63	50	0.5006	0.6235	0.5553
		- idf
			ccb	kmeans-idf	0127	38	50	0.6639	0.4412	0.5301
			ccb	kmeans-idf	0210	52	50	0.5619	0.5995	0.5801
			ccb	kmeans-idf	0419	51	50	0.6557	0.7113	0.6824
			ccb	kmeans-idf	0512	44	50	0.7906	0.4660	0.5864
			ccb	kmeans-idf	1012	58	50	0.4844	0.4273	0.4541
			ben	kmeans-idf	0127	34	50	0.8476	0.2822	0.4235
			ben	kmeans-idf	0210	58	50	0.5368	0.6917	0.6045
			ben	kmeans-idf	0419	59	50	0.6397	0.8333	0.7238
			ben	kmeans-idf	0512	34	50	1.0000	0.4389	0.6100
			ben	kmeans-idf	1012	65	50	0.4556	0.6538	0.5370
			bahn	kmeans-idf	0127	43	50	0.5673	0.4602	0.5082
			bahn	kmeans-idf	0210	63	50	0.4529	0.7255	0.5577
			bahn	kmeans-idf	0419	63	50	0.6009	0.9649	0.7406
			bahn	kmeans-idf	0512	37	50	0.9394	0.4509	0.6093
			bahn	kmeans-idf	1012	63	50	0.5444	0.6975	0.6116
		- tf-idf
			ccb	kmeans-tfidf	0127	38	50	0.6554	0.4442	0.5295
			ccb	kmeans-tfidf	0210	52	50	0.5564	0.4384	0.4904
			ccb	kmeans-tfidf	0419	51	50	0.6050	0.5348	0.5677
			ccb	kmeans-tfidf	0512	44	50	0.7525	0.4678	0.5769
			ccb	kmeans-tfidf	1012	58	50	0.4455	0.3678	0.4030
			ben	kmeans-tfidf	0127	34	50	0.8883	0.3071	0.4565
			ben	kmeans-tfidf	0210	58	50	0.4649	0.4577	0.4613
			ben	kmeans-tfidf	0419	59	50	0.5058	0.5933	0.5461
			ben	kmeans-tfidf	0512	34	50	0.8889	0.3885	0.5407
			ben	kmeans-tfidf	1012	65	50	0.4756	0.6410	0.5460
			bahn	kmeans-tfidf	0127	43	50	0.6152	0.4552	0.5233
			bahn	kmeans-tfidf	0210	63	50	0.4254	0.5506	0.4800
			bahn	kmeans-tfidf	0419	63	50	0.5133	0.7123	0.5967
			bahn	kmeans-tfidf	0512	37	50	0.8283	0.4040	0.5431
			bahn	kmeans-tfidf	1012	63	50	0.4756	0.6471	0.5482
